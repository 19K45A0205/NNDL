{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2183 entries, 0 to 2182\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   load    2183 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 17.2 KB\n",
      "(array([928], dtype=int64),)\n",
      "3377.9196\n",
      "3377.9196\n",
      "8841.66948\n",
      "8841.66948\n",
      "0.8169544215005555 0.13719107428858718\n",
      "training data mean squared error: 0.016822233203693252\n",
      "Testing data mean squared error: 0.019586687219796544\n",
      "model parameter: 0.8169544215005555 0.13719107428858718\n"
     ]
    }
   ],
   "source": [
    "# NESTEROV ACCELERATED GRADIENT DESCENT\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "load_data = pd.read_excel(r\"C:\\Users\\Krishnasai\\Load Data in kW (1).xlsx\")\n",
    "load_data.head()\n",
    "\n",
    "type(load_data)\n",
    "\n",
    "data = load_data.rename(columns={5551.82208:'load'},inplace=False)\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.shape\n",
    "\n",
    "data.describe()\n",
    "\n",
    "data.info()\n",
    "\n",
    "data.corr()\n",
    "\n",
    "# VALIDATING NULL VALUE\n",
    "\n",
    "data.isnull().sum()\n",
    "\n",
    "# VISUALISING OUTLIERS OF DATA\n",
    "\n",
    "sns.boxplot(x=data['load'])\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "z = np.abs(stats.zscore(load_data.iloc[:,0]))\n",
    "\n",
    "threshold = 3\n",
    "print(np.where(z > 3))\n",
    "\n",
    "#From boxplot and from above zscore calculation, we can conclude that there is one outlier. lets replace it.\n",
    "\n",
    "data.iloc[928,0] = data.iloc[927,0]\n",
    "\n",
    "#AFTER REPLACING THE OUTLIER\n",
    "\n",
    "sns.boxplot(x=data['load'])\n",
    "\n",
    "#now all outliers are removed and now we are good to train the model\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in range(0,len(data)-1):\n",
    "  data_x.append(data.iloc[i,0])\n",
    "  data_y.append(data.iloc[i+1,0])\n",
    "\n",
    "plt.scatter(data_x,data_y)\n",
    "plt.title(\"load data visualisation\")\n",
    "plt.xlabel(\"previous hours load\")\n",
    "plt.ylabel(\"present hours load\")\n",
    "plt.grid()\n",
    "\n",
    "data_xx = pd.DataFrame(data_x)\n",
    "min_x = float(data_xx.min())\n",
    "max_x = float(data_xx.max())\n",
    "data_yy = pd.DataFrame(data_y)\n",
    "min_y = float(data_yy.min())\n",
    "max_y = float(data_yy.max())\n",
    "print(min_x)\n",
    "print(min_y)\n",
    "print(max_x)\n",
    "print(max_y)\n",
    "\n",
    "# DATA NORMALISATION\n",
    "\n",
    "x = minmax_scale(data_x)\n",
    "y = minmax_scale(data_y)\n",
    "\n",
    "data_norm = []\n",
    "for i in range(len(data)-24):\n",
    "    data_norm.append([x[i],y[i]])\n",
    "\n",
    "data_norm = pd.DataFrame(data_norm)\n",
    "data_norm\n",
    "\n",
    "# SPLITTING DATA SET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train,data_test = train_test_split(data_norm,test_size=0.1)\n",
    "\n",
    "data_norm.head()\n",
    "\n",
    "data_x = np.array(data_train[0])\n",
    "\n",
    "data_y = np.array(data_train[1])\n",
    "\n",
    "len(data_x)\n",
    "\n",
    "len(data_test)\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "\n",
    "#STEP 2: initialising required parameters\n",
    "m = 1\n",
    "c = -1\n",
    "iter = 1\n",
    "epochs = 2000\n",
    "alpha = 0.1\n",
    "ns = len(data_train)\n",
    "error = []\n",
    "vm = 0\n",
    "vc = 0\n",
    "moment = 0.9\n",
    "\n",
    "# while loop is runned until iter reaches epochs\n",
    "while (iter<=epochs):\n",
    "  # running for loop to calculate and update model parameters for each sample\n",
    "  for i in range(0,len(data_train)):\n",
    "    # calculating derivatives of m and c\n",
    "    der_m = (-1) * (data_y[i] - ((m+(moment*vm))*data_x[i]) - (c+(moment*vc)))*(data_x[i])\n",
    "    der_c = (-1) * (data_y[i] - ((m+(moment*vm))*data_x[i]) - (c+(moment*vc)))\n",
    "    # print(\"derivatives at \",i,\"   \",der_m,der_c)\n",
    "\n",
    "    # calculating change in m and c\n",
    "    vm = (moment * vm) - (alpha * der_m)\n",
    "    vc = (moment * vc) - (alpha * der_c)\n",
    "    # print(\"changes at \",i,vm,vc)\n",
    "\n",
    "    #updating m and c\n",
    "    m = m + vm\n",
    "    c = c + vc\n",
    "    # print(\"values at\",i,m,c)\n",
    "\n",
    "  err=0\n",
    "  for i in range(0,len(data_train)):\n",
    "    err+=((data_y[i] - (m * data_x[i]) - c))**2\n",
    "  err = (1/(2*len(data_train))) * err\n",
    "  error.append(err)\n",
    "    #incrementing no of iterations\n",
    "  iter = iter + 1\n",
    " \n",
    "\n",
    "  \n",
    "print(m,c)\n",
    "\n",
    "len(error)\n",
    "\n",
    "iters = np.arange(epochs)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred = []\n",
    "for i in range(len(data_train)):\n",
    "  pred.append(m*data_x[i] + c)\n",
    "\n",
    "mse_train = mean_squared_error(data_y,pred)\n",
    "\n",
    "data_test\n",
    "\n",
    "pred_test = m*data_test[0] + c\n",
    "mse_test = mean_squared_error(data_test[1],pred_test)\n",
    "\n",
    "# MEAN SQUARE ERRORS\n",
    "\n",
    "print(\"training data mean squared error:\",mse_train)\n",
    "print(\"Testing data mean squared error:\",mse_test)\n",
    "\n",
    "print(\"model parameter:\",m,c)\n",
    "\n",
    "#VISUALISING TRAINING DATA\n",
    "\n",
    "plt.scatter(data_train[0],data_train[1],label=\"original data points\")\n",
    "plt.plot(data_train[0],pred,color='red',label=\"predicted line\")\n",
    "plt.title(\"visualing regression line of training data\")\n",
    "plt.xlabel(\"previous hours load\")\n",
    "plt.ylabel(\"present hours load\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "#VISUALISING TESTING DATA\n",
    "\n",
    "plt.scatter(data_test[0],data_test[1],label=\"original data points\")\n",
    "plt.plot(data_test[0],pred_test,color='red',label=\"predicted line\")\n",
    "plt.title(\"visualing regression line of testing data\")\n",
    "plt.xlabel(\"previous hours load\")\n",
    "plt.ylabel(\"present hours load\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "#DEPLOYMENT OF MODEL\n",
    "\n",
    "input_load = float(input(\"enter yesterday load at this time : \"))\n",
    "input_load = (input_load - min_x)/(max_x-min_x)\n",
    "output_load = input_load*m+c\n",
    "\n",
    "output_load = output_load*(max_y-min_y)+min_y\n",
    "\n",
    "print(\"predicted load for this hour is : \",output_load)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
